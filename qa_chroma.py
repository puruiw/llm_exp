
import fix_sqlite

import os
import click
from dotenv import load_dotenv
from langchain_ollama.llms import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
from langfuse.callback import CallbackHandler

import chroma_lib

load_dotenv()


@click.command()
def run() -> None:
    langfuse_handler = CallbackHandler(
        secret_key=os.environ.get("LANGFUSE_SECRET_KEY"),
        public_key=os.environ.get("LANGFUSE_PUBLIC_KEY"),
        host="https://us.cloud.langfuse.com", # ğŸ‡ºğŸ‡¸ US region
    )

    embedding_model = chroma_lib.default_embedding_model()
    retriever = chroma_lib.get_sci_fi_retriever(embedding_model)
    docs = retriever.invoke("ä¸€æœ¬è®²è¿°å¤ªç©ºè´¸æ˜“çš„å°è¯´")
    for doc in docs:
        print(doc.metadata["source"])

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", "ä½ æ˜¯ä¸€åç§‘å¹»å°è¯´è¯„è®ºå®¶"),
            ("human", "é˜…è¯»ä¸‹é¢çš„å†…å®¹ {material}, å›ç­”é—®é¢˜: {question}"),
        ]
    )
    model = OllamaLLM(model="deepseek-r1:7b")
    chain = prompt | model
    result = chain.invoke({
        "material": docs[0],
        "question": "å°è¯´çš„ä¸»è¦äººç‰©æœ‰å“ªäº›ï¼Ÿ",
    }, config={
        "callbacks": [langfuse_handler],
    })
    print(result)


if __name__ == "__main__":
    run()
