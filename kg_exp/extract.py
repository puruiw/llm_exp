import os

import click
import dotenv
from langchain_experimental.graph_transformers import LLMGraphTransformer
from langchain_community.llms import VLLM
from langchain_ollama import OllamaLLM
from langchain_core.documents import Document

from langfuse.callback import CallbackHandler

dotenv.load_dotenv()


@click.command()
@click.option("--backend", default="ollama", help="LLM backend")
@click.option("--model", default="qwen3:8b", help="Model name")
@click.option("--temperature", default=0.0, type=float, help="Temperature for the LLM")
@click.option("--debug", is_flag=True, help="Enable debug mode")
def extract(backend: str, model: str, temperature: float, debug: bool) -> None:
    """
    Extract knowledge graph from the input text file and print the nodes and relationships.
    """
    if debug:
        langfuse_handler = CallbackHandler(
            secret_key=os.environ.get("LANGFUSE_SECRET_KEY"),
            public_key=os.environ.get("LANGFUSE_PUBLIC_KEY"),
            host="https://us.cloud.langfuse.com",  # ğŸ‡ºğŸ‡¸ US region
        )

    if backend == "vllm":
        llm = VLLM(
            model=model,
            trust_remote_code=True,
            temperature=temperature,
            vllm_kwargs={"gpu_memory_utilization": 0.7},
        )
    else:
        llm = OllamaLLM(model=model, temperature=temperature)

    llm_transformer = LLMGraphTransformer(llm=llm)

    # text = """
    # Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.
    # She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.
    # Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.
    # She was, in 1906, the first woman to become a professor at the University of Paris.
    # """

    text = """
    å´è¯´å‘¨ç‘œé—»è¯¸è‘›ç‘¾ä¹‹è¨€ï¼Œè½¬æ¨å­”æ˜ï¼Œå­˜å¿ƒæ¬²è°‹æ€ä¹‹ã€‚æ¬¡æ—¥ç‚¹é½å†›å°†ï¼Œå…¥è¾å­™æƒã€‚æƒæ›°ï¼šâ€œå¿å…ˆè¡Œï¼Œå­¤å³èµ·å…µç»§åã€‚â€ç‘œè¾å‡ºï¼Œä¸ç¨‹æ™®ã€é²è‚ƒï¼Œé¢†å…µèµ·è¡Œï¼Œä¾¿é‚€å­”æ˜åŒå¾€ã€‚å­”æ˜æ¬£ç„¶ä»ä¹‹ï¼Œä¸€åŒç™»èˆŸï¼Œé©¾èµ·å¸†æ¨¯ï¼Œè¿¤é€¦æœ›å¤å£è€Œè¿›ã€‚ç¦»ä¸‰æ±Ÿå£äº”å…­åé‡Œï¼Œèˆ¹ä¾æ¬¡ç¬¬æ­‡å®šã€‚å‘¨ç‘œåœ¨ä¸­å¤®ä¸‹å¯¨ï¼Œå²¸ä¸Šä¾è¥¿å±±ç»“è¥ï¼Œå‘¨å›´å±¯ä½ã€‚å­”æ˜åªåœ¨ä¸€å¶å°èˆŸå†…å®‰èº«ã€‚

    å‘¨ç‘œåˆ†æ‹¨å·²å®šï¼Œä½¿äººè¯·å­”æ˜è®®äº‹ã€‚å­”æ˜è‡³ä¸­å†›å¸ï¼Œå™ç¤¼æ¯•ã€‚ç‘œæ›°ï¼šâ€œæ˜”æ›¹æ“å…µå°‘ï¼Œè¢ç»å…µå¤šï¼Œè€Œæ“åèƒœç»è€…ï¼Œå› ç”¨è®¸æ”¸ä¹‹è°‹ï¼Œå…ˆæ–­ä¹Œå·¢ä¹‹ç²®ä¹Ÿã€‚ä»Šæ“å…µå…«åä¸‰ä¸‡ï¼Œæˆ‘å…µåªäº”å…­ä¸‡ï¼Œå®‰èƒ½æ‹’ä¹‹ï¼Ÿäº¦å¿…é¡»å…ˆæ–­æ“ä¹‹ç²®ï¼Œç„¶åå¯ç ´ã€‚æˆ‘å·²æ¢çŸ¥æ“å†›ç²®è‰ï¼Œä¿±å±¯äºèšé“å±±ã€‚å…ˆç”Ÿä¹…å±…æ±‰ä¸Šï¼Œç†ŸçŸ¥åœ°ç†ã€‚æ•¢çƒ¦å…ˆç”Ÿä¸å…³ã€å¼ ã€å­é¾™è¾ˆï¼Œå¾äº¦åŠ©å…µåƒäººï¼Œæ˜Ÿå¤œå¾€èšé“å±±æ–­æ“ç²®é“ã€‚å½¼æ­¤å„ä¸ºä¸»äººä¹‹äº‹ï¼Œå¹¸å‹¿æ¨è°ƒã€‚â€ 
    """

    documents = [Document(page_content=text)]
    callbacks = []
    if debug:
        callbacks.append(langfuse_handler)
    graph_documents = llm_transformer.convert_to_graph_documents(
        documents, config={"callbacks": callbacks}
    )
    print(f"Nodes:{graph_documents[0].nodes}")
    print(f"Relationships:{graph_documents[0].relationships}")


if __name__ == "__main__":
    extract()
